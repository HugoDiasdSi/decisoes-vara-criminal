"""
Aplicativo Hugging Face Spaces - Assessor Jur√≠dico Criminal
Sistema RAG para elabora√ß√£o de decis√µes judiciais baseado em banco de conhecimento
"""

import gradio as gr
import os
from pathlib import Path
import json
from typing import List, Dict, Tuple
import google.generativeai as genai
from utils.pdf_extractor import extract_text_from_pdf
from utils.rag_system import RAGSystem
from utils.prompt_builder import build_full_prompt

# Configura√ß√£o da API do Gemini
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# Inicializar sistema RAG
rag_system = RAGSystem()

def load_knowledge_base():
    """Carrega todas as minutas e metadados no sistema RAG"""
    try:
        # Carregar metadados
        with open("minutas_metadata.json", "r", encoding="utf-8") as f:
            metadata = json.load(f)

        # Carregar todas as minutas
        minutas_dir = Path(".")
        for item in metadata:
            filename = item["filename"]
            filepath = minutas_dir / filename

            if filepath.exists():
                with open(filepath, "r", encoding="utf-8") as f:
                    content = f.read()

                # Adicionar ao sistema RAG
                rag_system.add_document(
                    filename=filename,
                    content=content,
                    tags=item.get("tags", []),
                    description=item.get("descricao", "")
                )

        return True, f"Base de conhecimento carregada: {len(metadata)} minutas"
    except Exception as e:
        return False, f"Erro ao carregar base de conhecimento: {str(e)}"

def process_case(pdf_files, task_description, user_context=""):
    """
    Processa os autos digitais e gera a decis√£o judicial

    Args:
        pdf_files: Lista de arquivos PDF dos autos
        task_description: Descri√ß√£o da tarefa (ex: "elaborar decis√£o", "analisar den√∫ncia")
        user_context: Contexto adicional fornecido pelo usu√°rio
    """
    try:
        if not GEMINI_API_KEY:
            return "‚ö†Ô∏è API Key do Gemini n√£o configurada. Configure a vari√°vel de ambiente GEMINI_API_KEY."

        # ETAPA 1: Extrair texto dos PDFs
        extracted_texts = []
        status_msg = "üìÑ Extraindo texto dos PDFs...\n"

        if pdf_files:
            for pdf_file in pdf_files:
                text = extract_text_from_pdf(pdf_file.name)
                extracted_texts.append({
                    "filename": os.path.basename(pdf_file.name),
                    "content": text
                })
                status_msg += f"‚úì {os.path.basename(pdf_file.name)}\n"
        else:
            return "‚ö†Ô∏è Nenhum arquivo PDF foi fornecido."

        # ETAPA 2: An√°lise inicial e busca de minutas relevantes
        status_msg += "\nüîç Analisando autos e buscando minutas relevantes...\n"

        # Concatenar todo o conte√∫do extra√≠do
        full_text = "\n\n---\n\n".join([
            f"### {doc['filename']}\n{doc['content']}"
            for doc in extracted_texts
        ])

        # Buscar minutas relevantes usando RAG
        relevant_minutas = rag_system.search_relevant_minutas(
            query=f"{task_description} {user_context}",
            top_k=3
        )

        status_msg += f"‚úì {len(relevant_minutas)} minutas relevantes encontradas\n"
        for i, minuta in enumerate(relevant_minutas, 1):
            status_msg += f"  {i}. {minuta['filename']}\n"

        # ETAPA 3: Construir prompt completo
        status_msg += "\n‚öôÔ∏è Preparando an√°lise jur√≠dica...\n"

        full_prompt = build_full_prompt(
            autos_text=full_text,
            task=task_description,
            context=user_context,
            relevant_minutas=relevant_minutas
        )

        # ETAPA 4: Processar com Gemini
        status_msg += "\nü§ñ Processando com IA (isso pode levar alguns minutos)...\n"

        model = genai.GenerativeModel('gemini-1.5-pro-latest')

        # Configura√ß√£o para respostas longas
        generation_config = {
            "temperature": 0.3,
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 8192,
        }

        response = model.generate_content(
            full_prompt,
            generation_config=generation_config
        )

        # ETAPA 5: Formatar resposta
        result = f"""
{status_msg}

{'='*80}
RESULTADO DA AN√ÅLISE
{'='*80}

{response.text}

{'='*80}
MINUTAS CONSULTADAS
{'='*80}

"""
        for i, minuta in enumerate(relevant_minutas, 1):
            result += f"\n{i}. **{minuta['filename']}**\n"
            result += f"   {minuta['description']}\n"

        return result

    except Exception as e:
        return f"‚ùå Erro ao processar: {str(e)}\n\nDetalhes t√©cnicos: {type(e).__name__}"

def create_interface():
    """Cria a interface Gradio"""

    with gr.Blocks(
        title="Assessor Jur√≠dico Criminal - IA",
        theme=gr.themes.Soft()
    ) as demo:

        gr.Markdown("""
        # ‚öñÔ∏è Assessor Jur√≠dico Criminal - Sistema RAG

        Sistema de intelig√™ncia artificial para apoio √† elabora√ß√£o de decis√µes judiciais criminais,
        baseado em banco de conhecimento com minutas de decis√µes anteriores.

        ### üìã Como usar:
        1. Fa√ßa upload dos PDFs dos autos processuais
        2. Descreva a tarefa que deseja realizar
        3. Adicione contexto adicional se necess√°rio
        4. Clique em "Processar" e aguarde a an√°lise
        """)

        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### üìé Upload de Autos")
                pdf_input = gr.File(
                    label="Autos Digitais (PDFs)",
                    file_count="multiple",
                    file_types=[".pdf"],
                    type="filepath"
                )

                gr.Markdown("### üìù Tarefa")
                task_input = gr.Textbox(
                    label="Descri√ß√£o da tarefa",
                    placeholder="Ex: Elaborar decis√£o de recebimento da den√∫ncia\nAnalise preliminar para absolvi√ß√£o sum√°ria\nDecis√£o sobre pedido de liberdade provis√≥ria",
                    lines=3
                )

                context_input = gr.Textbox(
                    label="Contexto adicional (opcional)",
                    placeholder="Informa√ß√µes adicionais sobre o caso, peculiaridades, observa√ß√µes...",
                    lines=3
                )

                process_btn = gr.Button(
                    "üöÄ Processar",
                    variant="primary",
                    size="lg"
                )

            with gr.Column(scale=2):
                gr.Markdown("### üìÑ Resultado")
                output = gr.Textbox(
                    label="An√°lise e Decis√£o",
                    lines=30,
                    max_lines=50,
                    show_copy_button=True
                )

        gr.Markdown("""
        ---
        ### ‚ÑπÔ∏è Informa√ß√µes Importantes

        - **Sistema RAG**: Utiliza Retrieval-Augmented Generation para buscar minutas relevantes
        - **Base de conhecimento**: Mais de 70 minutas de decis√µes judiciais
        - **Modelo de IA**: Google Gemini 1.5 Pro
        - **OCR**: Suporta PDFs digitalizados e nativos

        ‚ö†Ô∏è **Aviso Legal**: Este sistema √© uma ferramenta de apoio. Todas as decis√µes devem ser revisadas
        por um magistrado antes de serem publicadas.

        üìö **Base de Conhecimento**: [GitHub Repository](https://github.com/HugoDiasdSi/decisoes-vara-criminal)
        """)

        # Event handlers
        process_btn.click(
            fn=process_case,
            inputs=[pdf_input, task_input, context_input],
            outputs=output
        )

        # Carregar base de conhecimento ao iniciar
        demo.load(
            fn=load_knowledge_base,
            outputs=None
        )

    return demo

# Inicializar e lan√ßar aplicativo
if __name__ == "__main__":
    # Carregar base de conhecimento
    success, message = load_knowledge_base()
    print(message)

    # Criar e lan√ßar interface
    demo = create_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )
